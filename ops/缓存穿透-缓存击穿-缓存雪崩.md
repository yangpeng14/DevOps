> - 作者：zeb_perfect
> - 链接：https://blog.csdn.net/zeb_perfect/article/details/54135506

## 前言

设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。

## 缓存穿透

缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。

![](/img/15519803-0f0dcb3dfba4ce8c.png)

### 解决方案：

#### 1. 将这个不存在的key预先设定一个值。比如，”key” , “&amp;&amp;”。在返回这个&amp;&amp;值的时候，应用层可以认为这是不存在的key，应用就可以进行相应的业务操作（继续等待、继续访问、放弃操作、...）；

![](/img/15519803-9ab184ab5b8075f1.png)
    

#### 2. 与第一种解决方案类似，只不过存放在缓存当中，查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个标识（如：&amp;&amp;）结果进行缓存，但它的过期时间会很短，最长不超过五分钟，异步进行数据库数据读取，获取到的值初始化到缓存里边；

![](/img/15519803-dd2c430406b8505a.png)

#### 3. 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力；

![](/img/15519803-f777eb6a200013cb.png)
    

## 缓存雪崩（很多数据）

缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。

### 解决方案

#### 1. 用加锁或者队列的方式保证缓存的单线程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上；

#### 2. 将缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。


## 缓存击穿（单个数据）


缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

### 解决方案：

#### 1.使用互斥锁（mutex key）

业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。

#### 2. “提前”使用互斥锁（mutex key）

在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。

#### 3. “永远不过期”（同数据库的“软”删除原理）

这里的“永远不过期”包含两层意思：

(1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。

(2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期。

从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程（非构建缓存的线程）可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。

![](/img/15519803-5162ccd8a8b96bd6.png)

#### 4. 资源保护（深入使用第3种，这种没有深入研究）

采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。


## 总结：没有最佳只有最合适

![](/img/15519803-376775e806efbaf4.png)

针对业务系统，永远都是具体情况具体分析，没有最好，只有最合适。